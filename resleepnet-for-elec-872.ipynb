{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Identify whether a CUDA-enabled GPU is available\nimport torch\n\nimport os\nimport copy\nimport mne\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mne.datasets.sleep_physionet.age import fetch_data\n%matplotlib inline\n\nif torch.cuda.is_available():\n    print('CUDA-enabled GPU found. Training should be faster.')\nelse:\n    print('No GPU found. Training will be carried out on CPU, which might be '\n          'slower.\\n\\nIf running on Google Colab, you can request a GPU runtime by'\n          ' clicking\\n`Runtime/Change runtime type` in the top bar menu, then '\n          'selecting \\'GPU\\'\\nunder \\'Hardware accelerator\\'.')\n    \nmne.set_log_level('ERROR')  # To avoid flooding the cell outputs with messages\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport os\n\n\n\n# Local directory where the dataset is stored\nlocal_dir = \"/kaggle/input/sleep-edf-and-apnea/sleep-edf-database-expanded-1.0.0/sleep-edf-database-expanded-1.0.0/sleep-cassette\"\n\n# Get all .edf files in the directory\nedf_files = sorted(glob.glob(os.path.join(local_dir, \"*.edf\")))\n\n\n# Initialize list to store file paths\nlist_small = []\nlist_big = []\n\n# Loop through each file\nfor i,edf_file in enumerate(edf_files):\n\n    \n    \n    directory_parts = edf_file.split(\"/\")\n\n    file_name = directory_parts[-1].split(\".\")[0]\n\n    signal_type=file_name.split(\"-\")[-1]\n    subject_name= file_name.split(\"-\")[0]\n\n    \n    if signal_type=='PSG':\n        list_small.append(edf_file)\n        \n        \n    elif signal_type=='Hypnogram':\n\n        hypnogram_path = os.path.join(local_dir, f\"{subject_name}-Hypnogram.edf\")\n\n        list_small.append(hypnogram_path)\n    \n        # Append list_small to list_big\n        list_big.append(list_small)\n\n        list_small = []\n#     if i==2:\n#         break\n# Display list_big\nprint(list_big[0])\nfnames1=list_big","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fnames = fnames1\nprint(len(fnames))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## DATASET FOR EXPERIMENT\n\n# fnames = fnames_cst  # ONLY IMPORT CST FILES  (78 subjects - 153 files)\n# # fnames = fnames_tlm  # ONLY IMPORT TLM FILES  (44 Subjects - 88 Files)\n# # fnames = fnames_cst+fnames_tml  # IMPORT BOTH CST AND TLM FILES (122 SUBJECTS)\n# print(len(fnames))\n\n\n'''We will import EEG signal 20 minutes before sleep and 0 or 1 minute after sleep\n   However, some sleep subjects does not have any record prior to sleep onset, for those we define before and after as 0 mins '''\n\ndef load_sleep_physionet_raw(raw_fname, annot_fname, load_eeg_only=True):   \n    try:\n        crop_wake_mins_start=20\n        crop_wake_mins_end=1\n        mapping = {'EOG horizontal': 'eog',\n                   'Resp oro-nasal': 'misc',\n                   'EMG submental': 'misc',\n                   'Temp rectal': 'misc',\n                   'Event marker': 'misc'}\n        exclude = mapping.keys() if load_eeg_only else ()\n        raw = mne.io.read_raw_edf(raw_fname, exclude=exclude, preload=True)    \n        # channels_to_pick = ['EEG Fpz-Cz','EEG Pz-Oz']\n        channels_to_pick = ['EEG Fpz-Cz']\n        raw.pick_channels(channels_to_pick)   \n        annots = mne.read_annotations(annot_fname)\n        raw.set_annotations(annots, emit_warning=False)    \n        if not load_eeg_only:            \n            raw.set_channel_types(mapping)   \n        if crop_wake_mins_start > 0: \n            mask = [x[-1] in ['1', '2', '3', '4', 'R']\n                    for x in annots.description]\n            sleep_event_inds = np.where(mask)[0]\n            tmin = annots[int(sleep_event_inds[0])]['onset'] - crop_wake_mins_start * 60\n            tmax = annots[int(sleep_event_inds[-1])]['onset'] + \\\n                   crop_wake_mins_end * 60 + annots[int(sleep_event_inds[-1])]['duration']\n            raw.crop(tmin=tmin, tmax=tmax)\n\n        ch_names = {i: i.replace('EEG ', '') \n                    for i in raw.ch_names if 'EEG' in i}\n        mne.rename_channels(raw.info, ch_names)\n        basename = os.path.basename(raw_fname)\n        subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n\n   \n        raw.info['subject_info'] = {'id': subj_nb}\n        raw.info['description'] = f\"rec_id:{rec_nb}\"\n\n    except:     \n        crop_wake_mins_start=0\n        crop_wake_mins_end=0\n        mapping = {'EOG horizontal': 'eog',\n                   'Resp oro-nasal': 'misc',\n                   'EMG submental': 'misc',\n                   'Temp rectal': 'misc',\n                   'Event marker': 'misc'}\n        exclude = mapping.keys() if load_eeg_only else ()\n        raw = mne.io.read_raw_edf(raw_fname, exclude=exclude, preload=True)     \n        channels_to_pick = ['EEG Fpz-Cz']  \n        # channels_to_pick = ['EEG Fpz-Cz','EEG Pz-Oz'] \n        raw.pick_channels(channels_to_pick)       \n        annots = mne.read_annotations(annot_fname)\n        raw.set_annotations(annots, emit_warning=False)  \n        if not load_eeg_only:            \n            raw.set_channel_types(mapping)   \n        if crop_wake_mins_start > 0: \n            mask = [x[-1] in ['1', '2', '3', '4', 'R']  \n                    for x in annots.description]         \n            sleep_event_inds = np.where(mask)[0]         \n            tmin = annots[int(sleep_event_inds[0])]['onset'] - crop_wake_mins_start * 60\n            tmax = annots[int(sleep_event_inds[-1])]['onset'] + \\\n                   crop_wake_mins_end * 60 + annots[int(sleep_event_inds[-1])]['duration']\n            raw.crop(tmin=tmin, tmax=tmax)\n\n        ch_names = {i: i.replace('EEG ', '') \n                    for i in raw.ch_names if 'EEG' in i}\n        mne.rename_channels(raw.info, ch_names)\n        basename = os.path.basename(raw_fname)\n        subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n\n    \n        raw.info['subject_info'] = {'id': subj_nb}\n        raw.info['description'] = f\"rec_id:{rec_nb}\"\n\n    return raw\n\nraws = []\nerror = []\nfor er,f in enumerate(fnames):\n    if er>=0:\n        try:\n            raw = load_sleep_physionet_raw(f[0], f[1])\n            raws.append(raw)\n        except Exception as e:\n            print(f\"Ignoring error: {e}\")\n            error.append(er)\n        if er==None:\n            break\n        if er%10==0 and er!=0:\n            print(f\"iteration completed:{er}\")\nprint(f\"Total files loaded: {len(raws)}\")\nprint(f\"Total error in anotation:{len(error)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset, ConcatDataset\n\ndef extract_epochs(raw, chunk_duration=30., epoch_length=5):\n    try:\n        annotation_desc_2_event_id = {\n            'Sleep stage W': 1,\n            'Sleep stage 1': 2,\n            'Sleep stage 2': 3,\n            'Sleep stage 3': 4,\n            'Sleep stage 4': 4,\n            'Sleep stage R': 5}\n        events, _ = mne.events_from_annotations(\n            raw, event_id=annotation_desc_2_event_id, \n            chunk_duration=chunk_duration)\n        event_id = {\n            'Sleep stage W': 1,\n            'Sleep stage 1': 2,\n            'Sleep stage 2': 3,\n            'Sleep stage 3/4': 4,\n            'Sleep stage R': 5}\n        tmax = 30. - (1. / raw.info['sfreq']) \n        picks = mne.pick_types(raw.info, eeg=True, eog=True)\n        epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n                            event_id=event_id, tmin=0., tmax=tmax, baseline=None)\n        data, labels = epochs.get_data(), epochs.events[:, 2] - 1\n        combined_data, combined_labels = [], []\n        for i in range(len(data) - epoch_length + 1):\n            combined_data.append(np.concatenate(data[i:i + epoch_length], axis=-1))\n            combined_labels.append(labels[i + epoch_length - 1])  \n    except:\n        annotation_desc_2_event_id_altr = {\n            'Sleep stage W': 1,\n            'Sleep stage 1': 2,\n            'Sleep stage 2': 3,\n            'Sleep stage R': 5}\n        events, _ = mne.events_from_annotations(\n            raw, event_id=annotation_desc_2_event_id, \n            chunk_duration=chunk_duration)\n        event_id = {\n            'Sleep stage W': 1,\n            'Sleep stage 1': 2,\n            'Sleep stage 2': 3,\n            'Sleep stage R': 5}\n        tmax = 30. - (1. / raw.info['sfreq'])  \n        picks = mne.pick_types(raw.info, eeg=True, eog=True)\n        epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n                            event_id=event_id, tmin=0., tmax=tmax, baseline=None)\n        data, labels = epochs.get_data(), epochs.events[:, 2] - 1\n        combined_data, combined_labels = [], []\n        for i in range(len(data) - epoch_length + 1):\n            combined_data.append(np.concatenate(data[i:i + epoch_length], axis=-1))\n            combined_labels.append(labels[i + epoch_length - 1]) \n    return np.array(combined_data), np.array(combined_labels)\n\n\n\nclass EpochsDataset(Dataset):\n    def __init__(self, epochs_data, epochs_labels, subj_nb=None, \n                 rec_nb=None, transform=None):\n        assert len(epochs_data) == len(epochs_labels)\n        self.epochs_data = epochs_data\n        self.epochs_labels = epochs_labels\n        self.subj_nb = subj_nb\n        self.rec_nb = rec_nb\n        self.transform = transform\n    def __len__(self):\n        return len(self.epochs_labels)\n    def __getitem__(self, idx):\n        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n        if self.transform is not None:\n            X = self.transform(X)\n        X = torch.as_tensor(X[None, ...])\n        return X, y\ndef scale(X):\n    X -= np.mean(X, axis=1, keepdims=True)\n    return X / np.std(X, axis=1, keepdims=True)\n\n\n\n\nimport os\n\nall_datasets = []\nerror_2 = []\nvalid_sub = []\n\nfor i, raw in enumerate(raws):\n    try:\n        # 1) Extract epochs\n        X_data, y_labels = extract_epochs(raw)\n\n        # 2) Parse subject and rec from filename\n        basename = os.path.basename(raw.filenames[0])   # e.g. 'SC4001E0-PSG.edf'\n        subj_nb = int(basename[3:5])                    # '40'\n        rec_nb = int(basename[5])                       # '0'\n\n        # 3) Build dataset\n        dataset = EpochsDataset(\n            X_data,\n            y_labels,\n            subj_nb=subj_nb,\n            rec_nb=rec_nb,\n            transform=scale\n        )\n        all_datasets.append(dataset)\n        valid_sub.append(subj_nb)\n\n    except Exception as e:\n        print(f\"found error in {i}\")\n        print(e)\n        error_2.append(i)\n\n    if i == 200:\n        break\n    if i % 10 == 0 and i != 0:\n        print(f\"Total Recording Loaded:{i}\")\n\nprint(f\"Total error file: {len(error_2)}\")\n\ndataset = ConcatDataset(all_datasets)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import LeavePGroupsOut\n\ndef pick_recordings(dataset, subj_rec_nbs):\n    pick_idx = list()                              \n    for subj_nb, rec_nb in subj_rec_nbs:\n        for i, ds in enumerate(dataset.datasets):\n            if (ds.subj_nb == subj_nb) and (ds.rec_nb == rec_nb):\n                pick_idx.append(i)\n    print(f\"test files: {pick_idx}\")           \n    remaining_idx = np.setdiff1d(\n        range(len(dataset.datasets)), pick_idx)\n    print(f\" train+val {remaining_idx}\")\n    pick_ds = ConcatDataset([dataset.datasets[i] for i in pick_idx])\n    if len(remaining_idx) > 0:\n        remaining_ds = ConcatDataset(\n            [dataset.datasets[i] for i in remaining_idx])\n    else:\n        remaining_ds = None    \n    return pick_ds, remaining_ds\n    \ndef train_test_split(dataset, n_groups, split_by='subj_nb'):\n    groups = [getattr(ds, split_by) for ds in dataset.datasets]\n    print(groups)\n    train_idx, test_idx = next(\n        LeavePGroupsOut(n_groups).split(X=groups, groups=groups))\n    print(len(train_idx))\n    print(len(test_idx))\n    train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n    test_ds = ConcatDataset([dataset.datasets[i] for i in test_idx]) \n    return train_ds, test_ds\n\nresult = []\nfst_sub = dataset.datasets[0].subj_nb\ntotal_sub=14   ## Number of subject in test set\nfor i in range(fst_sub,fst_sub+total_sub):\n    if i in [2, 4]:\n        continue\n    for j in range(1, 3):\n        result.append((i, j))\nprint(result)\ntest_recs = [(subj_nb, rec_nb)  \n             for subj_nb, rec_nb in result]\ntest_ds, train_ds = pick_recordings(dataset, test_recs)\n\n\n\nsplit = 25\nk = 1//split\n# k=0.02\n\nn_subjects_valid = max(1, int(len(train_ds.datasets) * k))\ntrain_ds, valid_ds = train_test_split(train_ds, n_subjects_valid, split_by='subj_nb')\nprint('Number of examples in each set:')\nprint(f'Number of Training Segments: {len(train_ds)}')\nprint(f'Number of Validation Segments: {len(valid_ds)}')\nprint(f'Number of Test Segments: {len(test_ds)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclasses_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\ny_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\nclass_order = [classes_mapping[i] for i in range(len(classes_mapping))]\nvalue_counts = y_train.value_counts()\nordered_value_counts = value_counts.reindex(class_order)\ncolors = sns.color_palette(\"BuGn_r\", len(class_order))\nfig, ax = plt.subplots()\n\nax.pie(ordered_value_counts,\n       labels=class_order,\n       colors=colors,\n       autopct='%1.1f%%',\n       startangle=90,\n       counterclock=False)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass SleepStagerSiam(nn.Module):\n    def __init__(self, n_channels, sfreq,Seq_Len,n_conv_chs=8, time_conv_size_s=0.50,\n                 max_pool_size_s=0.125, n_classes=5, input_size_s=30,\n                 dropout=0.25):\n        super().__init__()\n\n        time_conv_size = int(time_conv_size_s * sfreq)\n        max_pool_size = int(max_pool_size_s * sfreq)\n        input_size = int(input_size_s * sfreq)\n        input_size_1st = input_size\n        pad_size = time_conv_size // 2\n        self.n_channels = n_channels\n\n        if n_channels > 1:\n            self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n\n        self.feature_extractor1_1 = nn.Sequential(\n            nn.Conv2d(1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n            nn.ReLU(),\n            nn.MaxPool2d((1, max_pool_size))\n        )\n        \n        self.feature_extractor1_2 = nn.Sequential(\n            nn.Conv2d(1, n_conv_chs, (1, time_conv_size*2), padding=(0, pad_size*2+1)),\n            nn.ReLU(),\n            nn.MaxPool2d((1, max_pool_size))\n        )\n        \n        self.feature_extractor1_3 = nn.Sequential(\n            nn.Conv2d(1, n_conv_chs, (1, time_conv_size*4), padding=(0, 3 + pad_size*4)),\n            nn.ReLU(),\n            nn.MaxPool2d((1, max_pool_size))\n        )\n        \n        \n        \n        \n        i=32\n        self.lstm1 = nn.LSTM(input_size=n_conv_chs * n_channels*3, hidden_size=i, batch_first=True) #lstm er input size n_conv_chs * n_channels *2 hbe karon duita conv layer cat kora hoise\n        self.lstm2 = nn.LSTM(input_size=i, hidden_size=i, batch_first=True)\n        \n        self.lstm3 = nn.LSTM(input_size=i*2, hidden_size=i, batch_first=True)\n        self.lstm4 = nn.LSTM(input_size=i*3, hidden_size=i, batch_first=True)\n        # self.lstm5 = nn.LSTM(input_size=i*4, hidden_size=i, batch_first=True)\n        \n#         len_last_layer = 50 * (input_size // (max_pool_size ** 2))  # Adjusted for LSTM output size\n#         len_last_layer = 8000 * i//32\n        \n        len_last_layer = (Seq_Len*3000//12) * 32\n        self.fc = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(len_last_layer, n_classes)\n        )\n\n    def forward(self, x):\n        if self.n_channels > 1:\n            x = self.spatial_conv(x)\n            x = x.transpose(1, 2)\n#         print(f\"before mtcl{x.shape}\")\n        x1 = self.feature_extractor1_1(x)  # Shape: (128, 8, 2, 20)\n#         print(f\"after mtcl{x1.shape}\")\n        x2 = self.feature_extractor1_2(x)  # Shape: (128, 8, 2, 20)\n#         print(x2.shape)\n        x3 = self.feature_extractor1_3(x)\n        # x4 = self.feature_extractor1_4(x)\n        \n        x = torch.cat([x1, x2, x3], dim=1)  # Concatenate along filter dimension -> (128, 16, 2, 20)\n#         print(f\"after filter cat:{x.shape}\")\n\n        \n\n        x = x.view(x.size(0), -1, x.size(3))  # Reshape to (128, 32, 20)\n#         print(f\"before lstm1:{x.shape}\")\n        x = x.permute(0, 2, 1)  # Permute to (128, 20, 32)\n#         print(f\"before lstm1.1:{x.shape}\")\n        x_l1, _ = self.lstm1(x)  # LSTM expects input of shape (batch_size, seq_length, input_size)\n# #         print(f\"after lstm1:{x_l1.shape}\")\n        x_l2, _ = self.lstm2(x_l1)\n# #         print(f\"after lstm2:{x_l2.shape}\")\n        x_c1 = torch.cat([x_l1, x_l2], dim=2)\n# #         print(f\"after cat(ls1+ls2):{x_c1.shape}\")\n        x_l3, _ = self.lstm3(x_c1)\n# #         print(f\"after lstm3:{x_l3.shape}\")\n        x_c2 = torch.cat([x_l1, x_l2, x_l3], dim=2)\n#         print(f\"after cat(ls1+ls2+ls2):{x_c2.shape}\")\n        x_l4, _ = self.lstm4(x_c2)\n#         print(f\"after lstm4:{x.shape}\")\n        # x_c3 = torch.cat([x_l1, x_l2, x_l3, x_l4], dim=2)\n        # x_l5, _ = self.lstm5(x_c3)\n        x = x_l4\n        x = x.contiguous().view(x.size(0), -1)  # Flatten for fully connected layer\n#         print(f\"after flatten:{x.shape}\")\n        return self.fc(x)\n\n\n# sfreq = raws[0].info['sfreq']  # Sampling frequency\n# n_channels = raws[0].info['nchan']  # Number of channels\n\nsfreq = 100\nn_channels=1\nmodel = SleepStagerSiam(n_channels, sfreq, n_classes=5, Seq_Len=5)\nprint(f'Using device \\'{device}\\'.')\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create dataloaders\n# train_batch_size = 128  # Important hyperparameter\ntrain_batch_size = 512\nvalid_batch_size = 256  # Can be made as large as what fits in memory; won't impact performance\nnum_workers = 0  # Number of processes to use for the data loading process; 0 is the main Python process\n\nloader_train = DataLoader(\n    train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\nloader_valid = DataLoader(\n    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\nloader_test = DataLoader(\n    test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n\n\ny_pred_all, y_true_all = list(), list()\nfor batch_x, batch_y in loader_test:\n    batch_x = batch_x.to(device=device, dtype=torch.float32)\n    batch_y = batch_y.to(device=device, dtype=torch.int64)\n#     output = model.forward(batch_x)\n#     y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n    y_true_all.append(batch_y.cpu().numpy())\n    \n# y_pred = np.concatenate(y_pred_all)\ny_true = np.concatenate(y_true_all)\nrec_ids = np.concatenate(  # indicates which recording each example comes from\n    [[i] * len(ds) for i, ds in enumerate(test_ds.datasets)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport copy\nfrom sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, accuracy_score\n\ndef _do_train(model, loader, optimizer, criterion, device, metric):\n    # training loop\n    model.train()\n    \n    train_loss = np.zeros(len(loader))\n    y_pred_all, y_true_all = list(), list()\n    for idx_batch, (batch_x, batch_y) in enumerate(loader):\n        optimizer.zero_grad()\n        batch_x = batch_x.to(device=device, dtype=torch.float32)\n        batch_y = batch_y.to(device=device, dtype=torch.int64)\n\n        output = model(batch_x)\n        loss = criterion(output, batch_y)\n\n        loss.backward()\n        optimizer.step()\n        \n        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n        y_true_all.append(batch_y.cpu().numpy())\n\n        train_loss[idx_batch] = loss.item()\n        \n    y_pred = np.concatenate(y_pred_all)\n    y_true = np.concatenate(y_true_all)\n    perf = metric(y_true, y_pred)\n    \n    return np.mean(train_loss), perf\n        \n\ndef _validate(model, loader, criterion, device, metric):\n    # validation loop\n    model.eval()\n    \n    val_loss = np.zeros(len(loader))\n    y_pred_all, y_true_all = list(), list()\n    with torch.no_grad():\n        for idx_batch, (batch_x, batch_y) in enumerate(loader):\n            batch_x = batch_x.to(device=device, dtype=torch.float32)\n            batch_y = batch_y.to(device=device, dtype=torch.int64)\n            output = model.forward(batch_x)\n\n            loss = criterion(output, batch_y)\n            val_loss[idx_batch] = loss.item()\n            \n            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n            y_true_all.append(batch_y.cpu().numpy())\n            \n    y_pred = np.concatenate(y_pred_all)\n    y_true = np.concatenate(y_true_all)\n    perf = metric(y_true, y_pred)\n\n    return np.mean(val_loss), perf\n\n\ndef train(model, loader_train, loader_valid, optimizer, criterion, n_epochs, \n          patience, device, metric=None):\n   \n    best_valid_loss = np.inf\n    best_model_state = None\n    waiting = 0\n    history = list()\n    \n    if metric is None:\n        metric = accuracy_score\n        \n    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf')\n    print('-------------------------------------------------------------------')\n\n    for epoch in range(1, n_epochs + 1):\n        train_loss, train_perf = _do_train(\n            model, loader_train, optimizer, criterion, device, metric=metric)\n        valid_loss, valid_perf = _validate(\n            model, loader_valid, criterion, device, metric=metric)\n        history.append(\n            {'epoch': epoch, \n             'train_loss': train_loss, 'valid_loss': valid_loss,\n             'train_perf': train_perf, 'valid_perf': valid_perf})\n        \n        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}')\n\n        # model saving\n        if valid_loss < best_valid_loss:\n            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n            best_valid_loss = valid_loss\n            best_model_state = copy.deepcopy(model.state_dict())\n            waiting = 0\n        else:\n            waiting += 1\n\n        # model early stopping\n        if waiting >= patience:\n            print(f'Stop training at epoch {epoch}')\n            print(f'Best val loss : {best_valid_loss:.4f}')\n            break\n\n    # Load the best model state before returning\n    model.load_state_dict(best_model_state)\n    return model, history\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\ntrain_y = np.concatenate([ds.epochs_labels for ds in train_ds.datasets])\nclass_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\nclass_weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\n\noptimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\ncriterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epochs = 200\npatience = 35\n\n# best_model, history = train(\n#     model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, \n#     device, metric=cohen_kappa_score)\n\nbest_model, history = train(\n    model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, \n    device, metric=balanced_accuracy_score)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualizing the learning curves\n\nhistory_df = pd.DataFrame(history)\nax1 = history_df.plot(x='epoch', y=['train_loss', 'valid_loss'], marker='o')\nax1.set_ylabel('Loss')\nax2 = history_df.plot(x='epoch', y=['train_perf', 'valid_perf'], marker='o')\n# ax2.set_ylabel('Cohen\\'s kappa')\nax2.set_ylabel('Accuracy')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model.eval()\n\ny_pred_all, y_true_all = list(), list()\nfor batch_x, batch_y in loader_test:\n    batch_x = batch_x.to(device=device, dtype=torch.float32)\n    batch_y = batch_y.to(device=device, dtype=torch.int64)\n    output = model.forward(batch_x)\n    # print(batch_x.shape)\n    y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n    y_true_all.append(batch_y.cpu().numpy())\n    \ny_pred = np.concatenate(y_pred_all)\ny_true = np.concatenate(y_true_all)\nrec_ids = np.concatenate(  # indicates which recording each example comes from\n    [[i] * len(ds) for i, ds in enumerate(test_ds.datasets)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, cm_normalized, class_names, title='Confusion Matrix',\n                          cmap=plt.cm.Reds, linewidths=0.5, linecolor='k', save_path=None):\n    plt.figure(figsize=(6.2, 6))\n    \n    # Combine normalized values + raw counts into annotation text\n    annot = np.empty_like(cm).astype(str)\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            annot[i, j] = f\"{cm_normalized[i, j]*100:.1f}%\\n{cm[i, j]}\"\n    \n    sns.heatmap(cm_normalized, annot=annot, fmt=\"\", cmap=cmap,\n                xticklabels=class_names, yticklabels=class_names,\n                linewidths=1.5, linecolor=linecolor, cbar=False, annot_kws={\"size\": 12, \"weight\": 'bold'})\n    \n    # plt.title(title)\n    plt.ylabel('Ground Truth', fontweight='bold')\n    plt.xlabel('Predicted', fontweight='bold')\n    plt.xticks(fontsize=12, fontweight='bold')\n    plt.yticks(fontsize=12, fontweight='bold')\n    if save_path:\n        plt.savefig(save_path, format='jpg', bbox_inches='tight', dpi=1200)\n    plt.show()\n\n\n# Compute confusion matrix\nconf_mat = confusion_matrix(y_true, y_pred)\n\n# Normalize the confusion matrix per row (recall)\nconf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n\n# Class names from mapping\nclass_names = [classes_mapping[i] for i in range(len(classes_mapping))]\n\n# Save path\nsave_path = \"/kaggle/working/cm_uncertaintyyy_uncertain.jpg\"\n\n# Plot\nplot_confusion_matrix(conf_mat, conf_mat_normalized, class_names,\n                      cmap='Purples', linewidths=1.3, linecolor='k',\n                      save_path=save_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Example: y_true and y_pred for classification\ny_true_class = y_true\ny_pred_class = y_pred\n\n# Classification metrics\nprint(\"Accuracy:\", accuracy_score(y_true_class, y_pred_class))\nprint(\"Balanced Accuracy:\", balanced_accuracy_score(y_true_class, y_pred_class))\nprint(\"F1-Score (macro):\", f1_score(y_true_class, y_pred_class, average='macro'))\nprint(\"Precision (macro):\", precision_score(y_true_class, y_pred_class, average='macro'))\nprint(\"Recall (macro):\", recall_score(y_true_class, y_pred_class, average='macro'))\ntest_kappa = cohen_kappa_score(y_true, y_pred)\nprint(f'Cohen\\'s kappa: {test_kappa:0.5f}')\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_true_class, y_pred_class))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n# Example: y_true and y_pred for classification\ny_true_class = y_true\ny_pred_class = y_pred\n\n# Calculate per-class F1 scores\nper_class_f1_scores = f1_score(y_true_class, y_pred_class, average=None)\n\n# Print per-class F1 scores\nfor i, score in enumerate(per_class_f1_scores):\n    print(f\"F1-Score for class {i}: {score:.5f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Assuming y_true, y_pred, and rec_ids are already defined\n\nmask = rec_ids == 0  # pick a recording number\n\n# Sampling frequency and epoch length\nfs = 100  # in Hz\nepoch_length = 30  # in seconds\n\n# Define the start and end times for the 2-hour period in hours\nstart_time = 0  # start time in hours\nend_time = start_time+7.0  # end time in hours\n\n# Convert start and end times to seconds\nstart_time_seconds = start_time * 3600\nend_time_seconds = end_time * 3600\n\n# Calculate the corresponding epoch indices\nstart_epoch = int(start_time_seconds / epoch_length)\nend_epoch = int(end_time_seconds / epoch_length)\n\n# Select the data for the specified 2-hour period\ny_true_period = y_true[mask][start_epoch:end_epoch]\ny_pred_period = y_pred[mask][start_epoch:end_epoch]\n\n# Create the time vector for the specified period\nt_period = np.arange(len(y_true_period)) * epoch_length / 3600 + start_time\n\nfig, ax = plt.subplots(figsize=(12, 3))\nax.plot(t_period, y_true_period, color='blue', label='Annotated by sleep experts')\nax.plot(t_period, y_pred_period, alpha=0.7, color='red', label='Predicted by our model')\nax.set_yticks([0, 1, 2, 3, 4])\nax.set_yticklabels(['W', 'N1', 'N2', 'N3', 'R'])\nax.set_xlabel('Time (h)')\nax.set_title(f'Hypnogram ({start_time}-{end_time} Hours)')\nax.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}